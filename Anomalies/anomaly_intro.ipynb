{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction to Anomaly Detection\n",
        "Anomaly Detection is used to identify rare items, events, or observations that differ significantly from the majority of the data.\n",
        "\n",
        "\n",
        "## CASE STUDY:  Credit Card Fraud\n",
        "\n",
        "### Background\n",
        "FICO (and American Express) both use anomaly detection to monitor transactions. Anomalous transactions are flagged for manual review to prevent fraud.\n",
        "\n",
        "### Data\n",
        "The dataset includes transaction amount, location, and frequency of transactions.\n",
        "\n",
        "### Solution\n",
        "Isolation Forest and similar techniques are used to detect transactions that deviate significantly from a user's normal behavior.\n",
        "\n",
        "### Results\n",
        "The system detects over 90% of fraudulent transactions, preventing losses and reducing risk for the bank.\n",
        "\n",
        "## Why Anomaly Detection Matters\n",
        "Anomalies can represent critical events:\n",
        "- **Fraud Detection**: Anomalous transactions could be fraudulent.\n",
        "- **Network Security**: Unusual activity may indicate an attack.\n",
        "- **Manufacturing**: Equipment failures may be detected through abnormal sensor readings.\n",
        "\n",
        "# Types of Anomalies\n",
        "1. **Point Anomalies**: One data point that is far from others (e.g., a high-value credit transaction).\n",
        "2. **Contextual Anomalies**: Points that are only anomalous in a given context (e.g., a spike in temperature that's unusual for a certain season).\n",
        "3. **Collective Anomalies**: A set of data points that, together, indicate abnormal behavior (e.g., repeated failed logins).\n",
        "\n",
        "# Popular Anomaly Detection Techniques\n",
        "1. **Statistical Methods**: Use statistics to identify outliers (e.g., Z-score, IQR).\n",
        "2. **Machine Learning Models**: Use algorithms like Isolation Forest, One-Class SVM, and Autoencoders.\n",
        "3. **Distance-Based Methods**: Identify outliers based on distance metrics (e.g., k-NN).\n",
        "4. **Density-Based Methods**: Detect anomalies based on local density (e.g., DBSCAN).\n",
        "\n",
        "---\n",
        "\n",
        "# Anomaly Detection with Isolation Forest\n",
        "Isolation Forest is an unsupervised learning algorithm that isolates anomalies by randomly partitioning the data.\n",
        "\n",
        "## How Isolation Forest Works\n",
        "- Randomly splits data points into partitions.\n",
        "- Anomalies are isolated faster, as they are easier to separate from the rest of the data.\n",
        "- Each point is assigned an \"anomaly score\" based on how quickly it gets isolated.\n",
        "\n",
        "# Simulating Data for Anomaly Detection\n",
        "Let's create a dataset with a few anomalous points."
      ],
      "metadata": {
        "id": "1xAxPqT7JsXl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_2BwETt2JZvI"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Generate normal data\n",
        "np.random.seed(42)\n",
        "data_normal = np.random.normal(loc=0, scale=1, size=(100, 2))\n",
        "\n",
        "# Add anomalies\n",
        "data_anomalous = np.random.uniform(low=-6, high=6, size=(5, 2))\n",
        "\n",
        "# Combine into a DataFrame\n",
        "data = np.vstack([data_normal, data_anomalous])\n",
        "df = pd.DataFrame(data, columns=['Feature_1', 'Feature_2'])\n",
        "\n",
        "# Visualize data\n",
        "plt.scatter(df['Feature_1'], df['Feature_2'], color='blue', label='Normal')\n",
        "plt.scatter(data_anomalous[:, 0], data_anomalous[:, 1], color='red', label='Anomalous')\n",
        "plt.xlabel('Feature_1')\n",
        "plt.ylabel('Feature_2')\n",
        "plt.legend()\n",
        "plt.title(\"Simulated Data with Anomalies\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Applying Isolation Forest for Anomaly Detection\n",
        "Let's use Isolation Forest to identify the anomalies in our data."
      ],
      "metadata": {
        "id": "SM7wcLsUKAag"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import IsolationForest\n",
        "\n",
        "# Initialize Isolation Forest\n",
        "iso_forest = IsolationForest(contamination=0.05, random_state=42)\n",
        "df['Anomaly_Score'] = iso_forest.fit_predict(df[['Feature_1', 'Feature_2']])\n",
        "\n",
        "# Separate the results\n",
        "normal = df[df['Anomaly_Score'] == 1]\n",
        "anomalies = df[df['Anomaly_Score'] == -1]\n",
        "\n",
        "# Display number of anomalies detected\n",
        "print(\"Number of anomalies detected:\", len(anomalies))"
      ],
      "metadata": {
        "id": "lODNVpd3KBV1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualizing the Results\n",
        "Let's plot the data to see which points were detected as anomalies."
      ],
      "metadata": {
        "id": "LEyNQMnEKKPn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(normal['Feature_1'], normal['Feature_2'], color='blue', label='Normal')\n",
        "plt.scatter(anomalies['Feature_1'], anomalies['Feature_2'], color='red', label='Anomalous')\n",
        "plt.xlabel('Feature_1')\n",
        "plt.ylabel('Feature_2')\n",
        "plt.legend()\n",
        "plt.title(\"Anomaly Detection with Isolation Forest\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1IVR9C-3KGE5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluating Model Performance\n",
        "In real-world cases, we would evaluate based on precision, recall, and F1 score for anomaly detection. However, in an unsupervised setting, this is challenging without labeled data.\n",
        "\n",
        "## Tips for Real-World Evaluation\n",
        "- **Labeling Small Sample**: Label a small sample of data for evaluation.\n",
        "- **Manual Inspection**: Manually review flagged anomalies.\n",
        "- **Compare with Baseline**: Use historical anomaly data as a baseline.\n",
        "\n",
        "# Best Practices for Anomaly Detection\n",
        "- **Use Domain Knowledge**: Understand the specific context to refine your anomaly detection approach.\n",
        "- **Optimize Threshold**: Adjust the anomaly detection threshold to balance sensitivity and specificity.\n",
        "- **Combine with Other Techniques**: Use multiple techniques (e.g., statistical and machine learning-based methods) for more reliable detection.\n",
        "- **Monitor Regularly**: Anomaly patterns may change over time, so periodic retraining is beneficial.\n",
        "\n"
      ],
      "metadata": {
        "id": "T5_q0irGKPVY"
      }
    }
  ]
}