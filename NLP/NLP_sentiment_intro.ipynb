{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction to Natural Language Processing\n",
        "Natural Language Processing (NLP) enables machines to interpret, understand, and generate human language.\n",
        "Applications of NLP include chatbots, machine translation, and sentiment analysis."
      ],
      "metadata": {
        "id": "Df3ZrTdskfhg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vBHxTKiWkUhS",
        "outputId": "c8610629-dcb6-4d18-8933-ae4f4228e93f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "# Import necessary libraries for NLP\n",
        "import nltk\n",
        "import spacy\n",
        "from transformers import pipeline\n",
        "\n",
        "\n",
        "# Download any necessary NLTK resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Understanding Sentiment Analysis\n",
        "Sentiment analysis is the process of identifying and classifying sentiments within text. It is widely used in various\n",
        "industries to understand public opinion, customer feedback, and more."
      ],
      "metadata": {
        "id": "Ne9ZkjqckgYb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample text data to work with\n",
        "sample_texts = [\n",
        "  \"I absolutely love this product! It works like a charm.\",\n",
        "  \"This was a terrible experience; I am never coming back.\",\n",
        "  \"It was okay, not the best but not the worst either.\"\n",
        "]\n",
        "\n",
        "# Display sample texts\n",
        "for text in sample_texts:\n",
        "  print(text)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSNeYuUSksB_",
        "outputId": "97d96a50-9818-4de7-82d8-55dffe732d4e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I absolutely love this product! It works like a charm.\n",
            "This was a terrible experience; I am never coming back.\n",
            "It was okay, not the best but not the worst either.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Preprocessing Steps\n",
        "Preprocessing is a crucial step in NLP that involves preparing and cleaning the text for analysis. Common steps include:\n",
        "- **Tokenization**: Breaking down text into individual words or tokens\n",
        "- **Stopword Removal**: Removing \"common\" words that may not carry significant meaning (and, the, is, this...)\n",
        "\n",
        "- **Stemming/Lemmatization**: Reducing words to their root forms\n",
        "\n",
        ".\n",
        "<hr>\n",
        ".\n",
        "\n",
        "![Tokenize](https://miro.medium.com/v2/resize:fit:4800/format:webp/1*Rs6fzMD_9AFzSfNUguPlDA.jpeg)\n",
        "\n"
      ],
      "metadata": {
        "id": "yRq6w-OIkt8d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example of tokenization and stopword removal with NLTK\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Tokenize and remove stopwords from the sample text\n",
        "stop_words = set(stopwords.words('english'))\n",
        "processed_texts = []\n",
        "\n",
        "for text in sample_texts:\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    filtered_tokens = [word for word in tokens if word.isalnum() and word not in stop_words]\n",
        "    processed_texts.append(filtered_tokens)\n",
        "\n",
        "# Display processed text\n",
        "for i, tokens in enumerate(processed_texts):\n",
        "    print(f\"Original: {sample_texts[i]}\")\n",
        "    print(f\"Processed: {tokens}\\n\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00Jl46u3k4rr",
        "outputId": "0e3c0e23-1559-4340-e158-c0b7e16117c9"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original: I absolutely love this product! It works like a charm.\n",
            "Processed: ['absolutely', 'love', 'product', 'works', 'like', 'charm']\n",
            "\n",
            "Original: This was a terrible experience; I am never coming back.\n",
            "Processed: ['terrible', 'experience', 'never', 'coming', 'back']\n",
            "\n",
            "Original: It was okay, not the best but not the worst either.\n",
            "Processed: ['okay', 'best', 'worst', 'either']\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lemmatization\n",
        "\n",
        "Lemmatization is the process of reducing a word to its base or dictionary form, known as the lemma. It can help improve the accuracy of NLP tasks by grouping together different forms of the same word.\n",
        "\n",
        "The goal is to group together different inflected forms of a word so they can be analyzed as a single item. Unlike stemming, which simply chops off the ends of words, lemmatization considers the context and part of speech of the word to choose an actual valid root word.\n",
        "\n",
        "This is often more accurate than stemming, as it considers the word's context and part of speech.\n",
        "\n",
        "> For example, the lemma of \"running\" is \"run,\" and the lemma of \"better\" is \"good.\"\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vq_bHgx3md06"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "# Load the spaCy English language model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Example text\n",
        "text = \"I am running quickly, and I feel better now.\"\n",
        "\n",
        "# Process the text with spaCy\n",
        "doc = nlp(text)\n",
        "\n",
        "# Print the lemmas of each token\n",
        "for token in doc:\n",
        "    print(token.text.ljust(10), token.lemma_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9-J_QBwmmTG",
        "outputId": "46318a3b-fdca-4c69-96f8-ae93e0059926"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I          I\n",
            "am         be\n",
            "running    run\n",
            "quickly    quickly\n",
            ",          ,\n",
            "and        and\n",
            "I          I\n",
            "feel       feel\n",
            "better     well\n",
            "now        now\n",
            ".          .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Choosing a Sentiment Analysis Model\n",
        "Several libraries and models can perform sentiment analysis, including:\n",
        "- **Rule-based**: `TextBlob`, `VADER`\n",
        "- **Transformer-based**: BERT, DistilBERT\n",
        "Here, we will use `TextBlob` and Hugging Face's `transformers` library."
      ],
      "metadata": {
        "id": "F8LUXfxjlIWV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a pretrained sentiment analysis pipeline using Hugging Face's transformers\n",
        "sentiment_analyzer = pipeline(\"sentiment-analysis\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9uFje82lJAx",
        "outputId": "99cef08f-8ad1-4e12-b1b7-34a46972bbda"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hands-On Sentiment Analysis Example\n",
        "Let's analyze the sentiment of sample texts using both `TextBlob` and a transformer model.\n",
        "\n",
        "> Note: Using a free huggingface token"
      ],
      "metadata": {
        "id": "rnJjWRqMlSkf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import TextBlob for rule-based sentiment analysis\n",
        "from textblob import TextBlob\n",
        "\n",
        "# Analyze sentiment with TextBlob\n",
        "print(\"TextBlob Sentiment Analysis:\")\n",
        "for text in sample_texts:\n",
        "    blob = TextBlob(text)\n",
        "    print(f\"Text: {text}\\nSentiment: {blob.sentiment}\\n\")\n",
        "\n",
        "# Analyze sentiment with transformers\n",
        "print(\"Transformer-based Sentiment Analysis:\")\n",
        "for text in sample_texts:\n",
        "    result = sentiment_analyzer(text)[0]\n",
        "    print(f\"Text: {text}\\nSentiment: {result['label']}, Confidence: {result['score']:.2f}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ca_kgc7IlUT3",
        "outputId": "418afcff-9772-47b6-ae51-faff6e04d442"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TextBlob Sentiment Analysis:\n",
            "Text: I absolutely love this product! It works like a charm.\n",
            "Sentiment: Sentiment(polarity=0.625, subjectivity=0.6)\n",
            "\n",
            "Text: This was a terrible experience; I am never coming back.\n",
            "Sentiment: Sentiment(polarity=-0.5, subjectivity=0.5)\n",
            "\n",
            "Text: It was okay, not the best but not the worst either.\n",
            "Sentiment: Sentiment(polarity=0.16666666666666666, subjectivity=0.6)\n",
            "\n",
            "Transformer-based Sentiment Analysis:\n",
            "Text: I absolutely love this product! It works like a charm.\n",
            "Sentiment: POSITIVE, Confidence: 1.00\n",
            "\n",
            "Text: This was a terrible experience; I am never coming back.\n",
            "Sentiment: NEGATIVE, Confidence: 1.00\n",
            "\n",
            "Text: It was okay, not the best but not the worst either.\n",
            "Sentiment: POSITIVE, Confidence: 0.90\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Discussion of Model Performance and Limitations\n",
        "### Challenges:\n",
        "- **Context Sensitivity**: Models may misinterpret context, especially with sarcasm or irony.\n",
        "- **Domain-Specific Language**: Generic models might struggle with industry-specific terms.\n",
        "Improving sentiment analysis often requires high-quality, domain-specific datasets and, in some cases, custom fine-tuning of models.\n",
        "\n",
        "# Summary and Q&A\n",
        "In this session, we've covered:\n",
        "- Key NLP concepts\n",
        "- Steps for text preprocessing\n",
        "- Examples of sentiment analysis using TextBlob and transformer-based models.\n",
        "\n",
        "**Further Learning**:\n",
        "- Hugging Face Documentation: https://huggingface.co/docs\n",
        "- NLP courses: Online platforms like Coursera, edX, and DataCamp offer great resources.\n",
        "\n",
        "Feel free to explore further, and let’s open the floor for any questions!"
      ],
      "metadata": {
        "id": "eZgC8PCJlWBE"
      }
    }
  ]
}