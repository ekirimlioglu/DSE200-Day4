{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOFLDl8vHQ3S"
      },
      "source": [
        "# Introduction to Imbalanced Data\n",
        "\n",
        "In data science, we often encounter imbalanced datasets, where one class significantly outnumbers another. This can lead to biased models, as most machine learning algorithms assume balanced classes.  Why imbalance matter?\n",
        "\n",
        "- Models can perform poorly on minority classes, leading to false negatives or missed opportunities.\n",
        "- Common examples include fraud detection, rare disease diagnosis, and churn prediction.\n",
        "\n",
        "# What is SMOTE?\n",
        "SMOTE (Synthetic Minority Over-sampling Technique) handles imbalanced data by creating synthetic samples of the minority class.\n",
        "\n",
        "## How SMOTE Works\n",
        "- **Identify Minority Class**: SMOTE identifies the samples in the minority class.\n",
        "- **Generate Synthetic Samples**: New samples are created by interpolating between existing minority samples.\n",
        "- **Balanced Dataset**: The generated samples are added to the dataset to achieve a balanced class distribution.\n",
        "\n",
        "# Implementing SMOTE with Python\n",
        "We'll use the `imbalanced-learn`, a popular library for handling imbalanced data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MzYL1ttvGw5t"
      },
      "outputs": [],
      "source": [
        "# Install imbalanced-learn if not already installed\n",
        "%pip install -q imbalanced-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cSPKnrEQGyE_"
      },
      "source": [
        "# Simulating an Imbalanced Dataset\n",
        "Let's create a synthetic dataset to demonstrate the effects of SMOTE."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "a64IZ6N7G03R",
        "outputId": "179d2b8a-bf7f-4b08-eebd-d026c5eed160"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import make_classification\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Create a dataset with imbalance (90% class 0, 10% class 1)\n",
        "X, y = make_classification(n_samples=1000, n_features=2, n_informative=2, n_redundant=0,\n",
        "                           n_clusters_per_class=1, weights=[0.9, 0.1], random_state=42)\n",
        "\n",
        "# Convert to DataFrame for easier visualization\n",
        "data = pd.DataFrame(X, columns=['Feature_1', 'Feature_2'])\n",
        "data['Target'] = y\n",
        "data['Target'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fyWn5q-bG3cT"
      },
      "source": [
        "# Applying SMOTE\n",
        "Now, we'll use SMOTE to balance the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmXnX5v0G6Wo",
        "outputId": "aac04c91-e1d8-4f53-85be-eb9956d02e4e"
      },
      "outputs": [],
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "from collections import Counter\n",
        "\n",
        "# Display original class distribution\n",
        "print(\"Original Class Distribution:\", Counter(y))\n",
        "\n",
        "# Apply SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X_res, y_res = smote.fit_resample(X, y)\n",
        "\n",
        "# Display new class distribution\n",
        "print(\"Resampled Class Distribution:\", Counter(y_res))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igEb2dzuG9X-"
      },
      "source": [
        "# Visualizing SMOTE Results\n",
        "We’ll visualize the original and resampled datasets to see the effect of SMOTE."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "WdhmBGCMG-Hj",
        "outputId": "60e7d490-eca6-42c9-b8e6-d668e2b9bb4c"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot original data\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.scatter(data[data['Target'] == 0]['Feature_1'], data[data['Target'] == 0]['Feature_2'], label='Class 0', alpha=0.5)\n",
        "plt.scatter(data[data['Target'] == 1]['Feature_1'], data[data['Target'] == 1]['Feature_2'], label='Class 1', alpha=0.5)\n",
        "plt.title(\"Original Data\")\n",
        "plt.legend()\n",
        "\n",
        "# Plot resampled data\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.scatter(X_res[y_res == 0][:, 0], X_res[y_res == 0][:, 1], label='Class 0', alpha=0.5)\n",
        "plt.scatter(X_res[y_res == 1][:, 0], X_res[y_res == 1][:, 1], label='Class 1', alpha=0.5)\n",
        "plt.title(\"SMOTE Resampled Data\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_-fsm4WHBE9"
      },
      "source": [
        "# Evaluating Model Performance Before and After SMOTE\n",
        "We’ll train a classifier on the original and SMOTE-balanced datasets to see the impact on model performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ur60On82HCEs",
        "outputId": "f5e1f1f7-70c9-4e51-b343-1532309dab48"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Split the original dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train on original data\n",
        "clf_original = RandomForestClassifier(random_state=42)\n",
        "clf_original.fit(X_train, y_train)\n",
        "y_pred_original = clf_original.predict(X_test)\n",
        "\n",
        "# Print evaluation metrics for original data\n",
        "print(\"Original Data Classification Report:\\n\", classification_report(y_test, y_pred_original))\n",
        "\n",
        "# Split the SMOTE-resampled dataset\n",
        "X_train_res, X_test_res, y_train_res, y_test_res = train_test_split(X_res, y_res, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train on SMOTE data\n",
        "clf_smote = RandomForestClassifier(random_state=42)\n",
        "clf_smote.fit(X_train_res, y_train_res)\n",
        "y_pred_smote = clf_smote.predict(X_test_res)\n",
        "\n",
        "# Print evaluation metrics for SMOTE data\n",
        "print(\"SMOTE Data Classification Report:\\n\", classification_report(y_test_res, y_pred_smote))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvkUvmf1HIGd"
      },
      "source": [
        "# Case Study: Fraud Detection in Banking\n",
        "In fraud detection, genuine transactions outnumber fraudulent ones, leading to a highly imbalanced dataset.\n",
        "A bank used SMOTE to balance their data before training a model, helping it detect rare fraudulent transactions more accurately.\n",
        "\n",
        "## Steps Taken in the Case Study\n",
        "1. **Problem**: A significant class imbalance in transaction data, making it difficult for the model to learn patterns of fraud.\n",
        "2. **Solution**: The bank applied SMOTE to balance the data and improve recall for the minority class.\n",
        "3. **Results**: After applying SMOTE, the model's ability to correctly detect fraud improved by 30%.\n",
        "\n",
        "# Best Practices with SMOTE\n",
        "- **Use with Care**: SMOTE should be used only on the training data, never on test data.\n",
        "- **Combine with Other Techniques**: SMOTE can be paired with undersampling or other oversampling techniques.\n",
        "- **Not Suitable for All Problems**: SMOTE works well when classes are separable but may not help when classes overlap."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
